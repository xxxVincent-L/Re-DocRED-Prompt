{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ujson as json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openai\n",
    "import collections\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File definition and load\n",
    "\n",
    "# Noticeï¼š You need to change the path of file.\n",
    "\n",
    "test_file = './data/test_revised.json'\n",
    "relation_file = './data/relations.txt'\n",
    "\n",
    "docred_file = './data/docred-test.json'\n",
    "\n",
    "with open(test_file, \"r\") as fh:\n",
    "    data = json.load(fh)\n",
    "\n",
    "with open(docred_file, \"r\") as fh1:\n",
    "    docred_data = json.load(fh1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def vertex_process(vertex_set):\n",
    "    \n",
    "#     vertex = [item['name'] for item in vertex_set[0]]\n",
    "# #     print(vertex[1])\n",
    "    \n",
    "def relation_triple(labels, vertex_set,):\n",
    "    triples = []\n",
    "    head_entity = []\n",
    "    tail_entity = []\n",
    "    relation_labels = []\n",
    "    evidences = []\n",
    "    for sample in labels:\n",
    "        head_entity.append(vertex_set[sample['h']][0]['name'])\n",
    "        tail_entity.append(vertex_set[sample['t']][0]['name'])\n",
    "        relation_labels.append(rel_dict[sample['r']])\n",
    "        # evidences.append()\n",
    "            \n",
    "    triples = list(zip(head_entity,tail_entity,relation_labels))\n",
    "    \n",
    "    return triples\n",
    "\n",
    "# Entity's Type\n",
    "\n",
    "entity_type_dict = {\n",
    "    'MISC': 'not of a specific type',\n",
    "    'PER': 'person',\n",
    "    'ORG': 'organization',\n",
    "    'LOC': 'location',\n",
    "    'TIME': 'time',\n",
    "    'NUM': 'number'\n",
    "    \n",
    "}\n",
    "\n",
    "def entity_type(vertex_set):\n",
    "    \n",
    "    name_type_dict = collections.defaultdict(int)\n",
    "    for sample in vertex_set:\n",
    "#         name = vertex_set[sample['h']][0]['name']\n",
    "        name = sample[0]['name']\n",
    "        entity_type = sample[0]['type']\n",
    "#         entity_type = vertex_set[sample['h']][0]['type']\n",
    "        original_type = entity_type_dict[entity_type]\n",
    "        \n",
    "        name_type_dict[name] = original_type\n",
    "    \n",
    "    return name_type_dict\n",
    "\n",
    "def relation_combination(triple):\n",
    "\n",
    "    new_triple = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(triple):\n",
    "        merged = False\n",
    "        j = i + 1\n",
    "        while j < len(triple):\n",
    "            if triple[i][0] == triple[j][0] and triple[i][1] == triple[j][1]:\n",
    "                if not merged:\n",
    "                    temp = [triple[i][2], triple[j][2]]\n",
    "                    new_triple.append((triple[i][0], triple[i][1], temp))\n",
    "                    merged = True\n",
    "                triple.pop(j)\n",
    "            else:\n",
    "                j += 1\n",
    "        if not merged:\n",
    "            new_triple.append((triple[i][0], triple[i][1],[triple[i][2]]))\n",
    "        i += 1\n",
    "    return new_triple\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "[(0, 6, 'P577'), (0, 2, 'P175'), (10, 8, 'P131'), (8, 7, 'P17'), (10, 7, 'P17'), (2, 1, 'P27'), (8, 5, 'P30'), (0, 14, 'P577'), (2, 0, 'P800'), (8, 7, 'P131'), (10, 7, 'P131')]\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 22\n",
    "rel_dict = collections.defaultdict(int)\n",
    "\n",
    "# Display all the relations. \n",
    "def relations_design(relation_file, rel_dict):\n",
    "    with open(relation_file,'r') as rf:\n",
    "        relations = rf.readlines()\n",
    "    random.seed(SEED)\n",
    "    random.shuffle(relations)\n",
    "    print(\"RELATIONS:==================\")\n",
    "    print(relations)\n",
    "    output_rel_grp = []\n",
    "\n",
    "    output_rel = ''\n",
    "    for i, r in enumerate(relations):\n",
    "        \n",
    "\n",
    "        # Split the lable and relation\n",
    "        label = r.split(' ', 1)[0]\n",
    "        relation = r.split(' ', 1)[1][:-1]\n",
    "        \n",
    "        # Form the dictionary of label and relation\n",
    "        rel_dict[label] = relation\n",
    "        \n",
    "        # Generate the relation for prompt\n",
    "        temp = '- ' + relation +'\\n'\n",
    "\n",
    "        group_size = 30\n",
    "        output_rel +=   temp\n",
    "\n",
    "        if (i+1) % group_size == 0 or i == 95:\n",
    "            output_rel_grp.append(output_rel)    \n",
    "            output_rel = ''\n",
    "\n",
    "            \n",
    "            \n",
    "    return output_rel_grp\n",
    "\n",
    "# rel_in_prompt = relations_design(relation_file, rel_dict)\n",
    "\n",
    "\n",
    "def preprocess(article_data):\n",
    "    \n",
    "    # Read the conponents\n",
    "    \n",
    "    title = article_data['title']\n",
    "    vertex_set = article_data['vertexSet']\n",
    "    sentence = article_data['sents']\n",
    "    labels = article_data['labels']\n",
    "    \n",
    "    \n",
    "    # Paragraph Form -> Insight 1: Robustness of sentence.\n",
    "    sentence_list = [' '.join(s) for s in sentence]\n",
    "    paragraph = ' '.join(sentence_list)\n",
    "    words_list = paragraph.split(\" \")\n",
    "#     print(words_list[41], words_list[43])\n",
    "\n",
    "\n",
    "    # Process the relation and generate the triples\n",
    "    \n",
    "    rel_in_prompt = relations_design(relation_file, rel_dict)\n",
    "    triples = relation_combination(relation_triple(labels, vertex_set))\n",
    "    name_type_dict = entity_type(vertex_set)\n",
    "#     print(name_type_dict)\n",
    "    return triples, rel_in_prompt, paragraph, name_type_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Different Instructions\n",
    "def instructions_design():\n",
    "    \n",
    "    instruction = collections.defaultdict(int)\n",
    "    \n",
    "    instruction['baseline'] = 'Instruction: the paragraph is from an article of Wikipedia. Category the relation between the entity \"<SEP>\" and entity \"<SEP>\" to one or more available values, the available values are:'\n",
    "    instruction['reformulate'] = 'Instruction: the paragraph is from an article of Wikipedia. Specify the relations that exist between the entity \"<SEP>\" and entity \"<SEP>\" . '\n",
    "    instruction['attention'] = 'Attention: You are restricted to choose from the following relationships and if there are matching relationships below, please output the relations directly, otherwise output \"NONE\":\\n'\n",
    "    instruction['orderOfEntity'] = 'Instruction: the paragraph is from an article of Wikipedia.<SEP> For entity \"<SEP>\", what relationship is entity \"<SEP>\" to it?'\n",
    "    instruction['orderOfParagraph'] = 'Instruction: the paragraph is from an article of Wikipedia.<SEP> Specify the relations that exist between the entity \"<SEP>\" and entity \"<SEP>\" based on the paragraph.'\n",
    "    instruction['entityType'] = 'The type of the entity \"<SEP>\" is \"<SEP>\", and the type of the entity \"<SEP>\" is \"<SEP>\". '\n",
    "    instruction['evidence'] = 'The two entities show in the sentence: [<SEP>]'\n",
    "    \n",
    "    return instruction\n",
    "\n",
    "def prompt_design(head_entity,tail_entity, rel_in_prompt, paragraph, name_type_dict):\n",
    "    \n",
    "    head_type = name_type_dict[head_entity]\n",
    "    tail_type = name_type_dict[tail_entity]\n",
    "    \n",
    "    instructions = instructions_design()\n",
    "    instruction = [instructions['orderOfEntity']][0].split(\"<SEP>\")\n",
    "    type_instruction = [instructions['entityType']][0].split(\"<SEP>\")\n",
    "    \n",
    "    paragraph_instruction = instruction[0] +'\\n\"\"\"\\n' + paragraph + '\\n\"\"\"\\n'\n",
    "\n",
    "    type_instruction =  type_instruction[0]+ head_entity + type_instruction[1] + head_type + type_instruction[2]+ tail_entity + type_instruction[3] + tail_type + type_instruction[4]\n",
    "    \n",
    "    concat_instruction = instruction[1]+head_entity+instruction[2]+tail_entity+instruction[3]\n",
    "    \n",
    "    sentence_instruction = [instructions['orderOfParagraph']][0].split(\"<SEP>\")[0]\n",
    "    \n",
    "    handcrafted_prompt = paragraph_instruction+concat_instruction + '\\n' + instructions['attention'] + rel_in_prompt + '\\n'\n",
    "\n",
    "    return handcrafted_prompt\n",
    "                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gpt(my_prompt):\n",
    "    \n",
    "\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=my_prompt,\n",
    "        temperature=0.1,\n",
    "        max_tokens=256,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "\n",
    "    # response = openai.ChatCompletion.create(\n",
    "    #   model=\"gpt-3.5-turbo\",\n",
    "    #   messages=[\n",
    "    #         {\"role\": \"system\", \"content\": \"You are a helpful assistant to do a relation classification task.\"},\n",
    "    #         {\"role\": \"user\", \"content\": my_prompt},\n",
    "    #     ]\n",
    "    # )\n",
    "\n",
    "    return response\n",
    "\n",
    "def relation_classification(triples, rel_in_prompt_group, paragraph, name_type_dict):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    prediction = 0\n",
    "    for sample in triples:\n",
    "        head_entity = sample[0]\n",
    "        tail_entity = sample[1]\n",
    "        relations = sample[2]\n",
    "        output = ''\n",
    "        \n",
    "        for rel_in_prompt in rel_in_prompt_group:\n",
    "        \n",
    "            prompt = prompt_design(head_entity,tail_entity, rel_in_prompt, paragraph, name_type_dict)\n",
    "            print(\"Prompt==============\")\n",
    "            print(prompt)\n",
    "            print(\"Output==============\")\n",
    "            output_relation = gpt(prompt)[\"choices\"][0][\"text\"]\n",
    "            # output_relation = gpt(prompt)[\"choices\"][0]['message']['content']\n",
    "            print(output_relation)\n",
    "            output+=output_relation + '\\n'\n",
    "            time.sleep(0.5)\n",
    "        \n",
    "        print(\"The relation between \"+ head_entity+ ' and '+ tail_entity+ ' is:')\n",
    "#         print(output)\n",
    "        output = output.lower()\n",
    "        for relation in relations:\n",
    "            if relation in output:\n",
    "                correct+=1\n",
    "            total+=1\n",
    "        \n",
    "        \n",
    "        for line in output.split(\"\\n\"):\n",
    "            if line != 'none'and line != '' and line!='\\n':\n",
    "                print(\"line === \"+line+\"\\n\")\n",
    "                prediction+=1\n",
    "        \n",
    "        print('-----------TIME-------------------')\n",
    "        localtime = time.localtime()\n",
    "        result = time.strftime(\"%I:%M:%S %p\", localtime)\n",
    "        print(result)\n",
    "        print('-----------TIME-------------------')\n",
    "        \n",
    "#         time.sleep(10)\n",
    "\n",
    "#         print('\\n')\n",
    "        # break\n",
    "    return correct,total, prediction\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline prompt\n",
    "\n",
    "# Form the preprocessed dataset.\n",
    "\n",
    "def evaluation(fscore_record, i, correct, c, predictions,ground_truth_samples):\n",
    "    print(\"For first \"+ str(i+1)+ \" documents ==========\\n\")\n",
    "    precision = correct / predictions\n",
    "\n",
    "\n",
    "    recall = correct / ground_truth_samples\n",
    "\n",
    "    print(\"True positive in this round ====\"+str(c))\n",
    "    print(\"True positive in all rounds ====\"+str(correct))\n",
    "    print(\"Number of predictions: ====\"+str(predictions))\n",
    "    print(\"precision ====\"+str(precision))\n",
    "    print(\"ground_truth_samples ====\"+str(ground_truth_samples))\n",
    "    print(\"recall=======\"+ str(recall))\n",
    "\n",
    "    if(predictions == 0 or (precision + recall) == 0):\n",
    "        fscore_record.append('NA')\n",
    "        return \n",
    "\n",
    "    fscore = 2*precision*recall/(precision + recall)\n",
    "    fscore_record.append(fscore)\n",
    "\n",
    "    print(\"The f1-score of the GPT-3 model is : \"+ str(fscore))\n",
    "    \n",
    "    \n",
    "def batch(data):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    ground_truth_samples = 0\n",
    "    predictions = 0\n",
    "    fscore_record = []\n",
    "    print(\"The file contains \"+str(len(data))+\" documents\")\n",
    "    # For all the documents in the dataset\n",
    "    for i in range(len(data)):\n",
    "        article_data = data[i]\n",
    "        triples, rel_in_prompt_group, paragraph = preprocess(article_data)\n",
    "        print(triples)\n",
    "        c,t,pred = relation_classification(triples, rel_in_prompt_group, paragraph)\n",
    "        correct += c\n",
    "        total += t\n",
    "        predictions += pred\n",
    "        # ground_truth_samples += len(triples) # It's value acctually eaquals to 't'\n",
    "        ground_truth_samples +=t\n",
    "        \n",
    "\n",
    "        evaluation(fscore_record, i, correct, c, predictions,ground_truth_samples)\n",
    "    \n",
    "        if i == 0:\n",
    "            break\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
